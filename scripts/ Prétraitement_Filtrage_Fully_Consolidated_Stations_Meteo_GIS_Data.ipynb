{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMQ1ck94C8fe7Ul1XvkFdl6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# === Bloc 1 : Monter Google Drive ===\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"5NFXZd1NuC0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Bloc 2 : Détection des colonnes à supprimer ===\n","import pandas as pd\n","import gc\n","\n","INPUT_CONSOLIDATED_PATH = '/content/drive/MyDrive/Stage_CEFREM_Salma_2025/Data/Meteo/InSitu/Fully_Consolidated_Stations_Meteo_GIS_Data.csv'\n","CHUNKSIZE = 100_000\n","\n","# Lire l'en-tête\n","with open(INPUT_CONSOLIDATED_PATH, 'r') as f:\n","    header = f.readline().strip().split(',')\n","total_lines = sum(1 for _ in open(INPUT_CONSOLIDATED_PATH)) - 1\n","nan_counts = {col: 0 for col in header}\n","\n","# Compter les NaN\n","for chunk in pd.read_csv(INPUT_CONSOLIDATED_PATH, chunksize=CHUNKSIZE):\n","    for col in chunk.columns:\n","        nan_counts[col] += chunk[col].isna().sum()\n","    del chunk\n","    gc.collect()\n","\n","# Colonnes à 100% NaN\n","cols_100_nan = [col for col, count in nan_counts.items() if count == total_lines]\n","\n","# Colonnes à suffixes (_x, _y, _raw_data)\n","core_metadata_cols = ['NOM_USUEL', 'LAT', 'LON', 'ALTI']\n","suffixes = ['_x', '_y', '_raw_data']\n","cols_suffixes = [f\"{col}{suf}\" for col in core_metadata_cols for suf in suffixes if f\"{col}{suf}\" in header]\n","\n","# Sauvegarde\n","with open('/content/cols_to_drop_100_nan.txt', 'w') as f:\n","    for col in cols_100_nan:\n","        f.write(col + '\\n')\n","with open('/content/cols_to_remove_suffixes.txt', 'w') as f:\n","    for col in cols_suffixes:\n","        f.write(col + '\\n')\n"],"metadata":{"id":"DGWnuneQuFg1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Bloc 3 : Nettoyage du fichier CSV ===\n","OUTPUT_CLEANED_PATH = '/content/drive/MyDrive/Stage_CEFREM_Salma_2025/Data/Meteo/InSitu/Cleaned_Consolidated_Meteo_GIS_Data.csv'\n","critical_meta = ['LAT', 'LON', 'ALTI', 'ALTI_MNT', 'SLOPE', 'ASPECT']\n","\n","with open('/content/cols_to_drop_100_nan.txt') as f:\n","    drop_100 = [line.strip() for line in f]\n","with open('/content/cols_to_remove_suffixes.txt') as f:\n","    drop_suffix = [line.strip() for line in f]\n","cols_to_drop = list(set(drop_100 + drop_suffix))\n","\n","def reduce_mem_usage(df):\n","    for col in df.columns:\n","        if df[col].dtype == 'float64':\n","            df[col] = pd.to_numeric(df[col], downcast='float')\n","        elif df[col].dtype == 'int64':\n","            df[col] = pd.to_numeric(df[col], downcast='integer')\n","        elif df[col].dtype == 'object':\n","            if df[col].nunique() / len(df[col]) < 0.5:\n","                df[col] = df[col].astype('category')\n","    return df\n","\n","first = True\n","for chunk in pd.read_csv(INPUT_CONSOLIDATED_PATH, chunksize=CHUNKSIZE):\n","    chunk.drop(columns=[c for c in cols_to_drop if c in chunk.columns], inplace=True)\n","    if 'DATE' in chunk.columns:\n","        chunk['DATE'] = pd.to_datetime(chunk['DATE'], errors='coerce')\n","    if 'NUM_POSTE' in chunk.columns:\n","        chunk['NUM_POSTE'] = chunk['NUM_POSTE'].astype(str)\n","    chunk = reduce_mem_usage(chunk)\n","\n","    # Supprimer lignes avec NaN dans métadonnées GIS\n","    chunk.dropna(subset=[c for c in critical_meta if c in chunk.columns], inplace=True)\n","\n","    chunk.to_csv(OUTPUT_CLEANED_PATH, mode='w' if first else 'a', index=False, header=first)\n","    first = False\n","    del chunk\n","    gc.collect()\n"],"metadata":{"id":"u167_TW8uIge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Bloc 4 : Filtrer à partir de 1970 ===\n","INPUT_CLEANED = OUTPUT_CLEANED_PATH\n","OUTPUT_FILTERED_PATH = '/content/drive/MyDrive/Stage_CEFREM_Salma_2025/Data/Meteo/InSitu/Filtered_1970_Consolidated_Meteo_GIS_Data.csv'\n","START_DATE = pd.to_datetime('1970-01-01')\n","\n","first = True\n","for chunk in pd.read_csv(INPUT_CLEANED, chunksize=CHUNKSIZE):\n","    if 'DATE' in chunk.columns:\n","        chunk['DATE'] = pd.to_datetime(chunk['DATE'], errors='coerce')\n","        filtered = chunk[chunk['DATE'] >= START_DATE].copy()\n","        filtered.to_csv(OUTPUT_FILTERED_PATH, mode='w' if first else 'a', index=False, header=first)\n","        first = False\n","        del filtered\n","    del chunk\n","    gc.collect()\n"],"metadata":{"id":"MpTl4Sb2uNbI"},"execution_count":null,"outputs":[]}]}