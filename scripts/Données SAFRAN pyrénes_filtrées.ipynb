{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymWOcU4-uJ_t"
   },
   "outputs": [],
   "source": [
    "# Installer les bibliothèques nécessaires\n",
    "!pip install geopandas shapely pandas --upgrade --quiet\n",
    "\n",
    "# Imports\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import os\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import gc\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "# Affichage des versions pour vérification\n",
    "print(f\"GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"Shapely version: {shapely.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO4XwhdCuM3j"
   },
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Chemins\n",
    "base_safran_folder = \"/content/drive/MyDrive/Stage_CEFREM_Salma_2025/Data/Meteo/SAFRAN/Safran_origine\"\n",
    "base_gis_folder = \"/content/drive/MyDrive/Stage_CEFREM_Salma_2025/Data/GIS\"\n",
    "chemin_fichier_pyrenees_shp = os.path.join(base_gis_folder, \"polygon_PYRENEES.shp\")\n",
    "chemin_fichier_sortie_global = os.path.join(base_safran_folder, \"Données_SAFRAN_Pyrenees_filtré_Final.csv\")\n",
    "\n",
    "# Liste des fichiers SAFRAN\n",
    "safran_files = [\n",
    "    \"QUOT_SIM2_1970-1979.csv\",\n",
    "    \"QUOT_SIM2_1980-1989.csv\",\n",
    "    \"QUOT_SIM2_1990-1999.csv\",\n",
    "    \"QUOT_SIM2_2000-2009.csv\",\n",
    "    \"QUOT_SIM2_2010-2019.csv\",\n",
    "    \"QUOT_SIM2_latest-20250601-20250714.csv\",\n",
    "    \"QUOT_SIM2_previous-2020-202506.csv\"\n",
    "]\n",
    "\n",
    "# CRS & colonnes\n",
    "crs_safran_initial = 'EPSG:27572'\n",
    "crs_cible_wgs84 = 'EPSG:4326'\n",
    "coord_col_x, coord_col_y = 'LAMBX', 'LAMBY'\n",
    "columns_to_keep = ['LAMBX', 'LAMBY', 'DATE', 'PRENEI_Q', 'PRELIQ_Q', 'T_Q']\n",
    "na_values_list = ['NA', 'N/A', 'NULL', '', ' ', '*****', '-9999']\n",
    "\n",
    "dtype_safran = {\n",
    "    'LAMBX': 'LAMBX', 'LAMBY': 'LAMBY', 'DATE': 'DATE',\n",
    "    'PRENEI_Q': 'SAFRAN_Snowfall_daily_mm',\n",
    "    'PRELIQ_Q': 'SAFRAN_Precipitation_liquid_daily_mm',\n",
    "    'T_Q': 'SAFRAN_Temperature_daily_C'\n",
    "}\n",
    "\n",
    "read_dtypes_optimized = {\n",
    "    'LAMBX': 'float32', 'LAMBY': 'float32', 'DATE': str,\n",
    "    'PRENEI_Q': 'float32', 'PRELIQ_Q': 'float32', 'T_Q': 'float32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zytxsqv_uQiG"
   },
   "outputs": [],
   "source": [
    "# Lecture et reprojection du shapefile\n",
    "gdf_pyrenees_polygon = gpd.read_file(chemin_fichier_pyrenees_shp)\n",
    "if gdf_pyrenees_polygon.crs != crs_cible_wgs84:\n",
    "    gdf_pyrenees_polygon = gdf_pyrenees_polygon.to_crs(crs_cible_wgs84)\n",
    "\n",
    "gdf_pyrenees_in_safran_crs = gdf_pyrenees_polygon.to_crs(crs_safran_initial)\n",
    "pyrenees_bounds_in_safran_crs = gdf_pyrenees_in_safran_crs.total_bounds\n",
    "pyrenees_union_geometry = gdf_pyrenees_polygon.unary_union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkRprJyeuUNJ"
   },
   "outputs": [],
   "source": [
    "def process_safran_file(filename, pyrenees_union_geometry, pyrenees_bounds_in_safran_crs, base_safran_folder,\n",
    "                        crs_safran_initial, crs_cible_wgs84,\n",
    "                        coord_col_x, coord_col_y, columns_to_keep,\n",
    "                        na_values_list, dtype_safran, read_dtypes_optimized):\n",
    "\n",
    "    path = os.path.join(base_safran_folder, filename)\n",
    "    all_chunks = []\n",
    "    chunksize = 200000\n",
    "    try:\n",
    "        for chunk in pd.read_csv(path, sep=';', decimal=',', encoding='utf-8', na_values=na_values_list,\n",
    "                                 usecols=columns_to_keep, chunksize=chunksize):\n",
    "            chunk = chunk.dropna(subset=[coord_col_x, coord_col_y])\n",
    "            chunk['LAMBX_m'] = chunk[coord_col_x] * 100\n",
    "            chunk['LAMBY_m'] = chunk[coord_col_y] * 100\n",
    "\n",
    "            minx, miny, maxx, maxy = pyrenees_bounds_in_safran_crs\n",
    "            chunk = chunk[(chunk['LAMBX_m'] >= minx) & (chunk['LAMBY_m'] >= miny) &\n",
    "                          (chunk['LAMBX_m'] <= maxx) & (chunk['LAMBY_m'] <= maxy)]\n",
    "            if chunk.empty:\n",
    "                continue\n",
    "\n",
    "            gdf = gpd.GeoDataFrame(chunk, geometry=gpd.points_from_xy(chunk['LAMBX_m'], chunk['LAMBY_m']),\n",
    "                                   crs=crs_safran_initial).to_crs(crs_cible_wgs84)\n",
    "            gdf = gdf[gdf.geometry.within(pyrenees_union_geometry)]\n",
    "\n",
    "            df = gdf.drop(columns=['geometry', 'LAMBX_m', 'LAMBY_m'])\n",
    "            df = df.rename(columns=dtype_safran)\n",
    "            all_chunks.append(df)\n",
    "\n",
    "        if all_chunks:\n",
    "            return pd.concat(all_chunks, ignore_index=True)\n",
    "        else:\n",
    "            return pd.DataFrame(columns=dtype_safran.values())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur : {e}\")\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame(columns=dtype_safran.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35TJLOP3ubOu"
   },
   "outputs": [],
   "source": [
    "# Traitement séquentiel simple pour commencer\n",
    "all_results = []\n",
    "for f in safran_files:\n",
    "    print(f\"Traitement de {f}...\")\n",
    "    df = process_safran_file(\n",
    "        f,\n",
    "        pyrenees_union_geometry,\n",
    "        pyrenees_bounds_in_safran_crs,\n",
    "        base_safran_folder,\n",
    "        crs_safran_initial,\n",
    "        crs_cible_wgs84,\n",
    "        coord_col_x,\n",
    "        coord_col_y,\n",
    "        columns_to_keep,\n",
    "        na_values_list,\n",
    "        dtype_safran,\n",
    "        read_dtypes_optimized\n",
    "    )\n",
    "    if not df.empty:\n",
    "        all_results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9g-UTfTdudHo"
   },
   "outputs": [],
   "source": [
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    final_df.to_csv(chemin_fichier_sortie_global, index=False, encoding='utf-8')\n",
    "    print(f\"\\n Données sauvegardées dans : {chemin_fichier_sortie_global}\")\n",
    "else:\n",
    "    print(\" Aucun résultat à sauvegarder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e72HEdjlugil"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_final = pd.read_csv(chemin_fichier_sortie_global, encoding='utf-8', decimal=',')\n",
    "    print(df_final.head())\n",
    "    print(df_final.info())\n",
    "except Exception as e:\n",
    "    print(f\" Lecture échouée : {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5iRggojBmqXxBytWz0Fgr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
