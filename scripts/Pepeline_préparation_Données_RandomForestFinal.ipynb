{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ip21QiInkWoI"
   },
   "outputs": [],
   "source": [
    "# === 1. IMPORTATIONS ET MONTAGE GOOGLE DRIVE ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import CRS, Transformer\n",
    "from scipy.spatial import cKDTree\n",
    "import gc  # Gestion mémoire\n",
    "from google.colab import drive\n",
    "\n",
    "print(f\"Répertoire de travail actuel : {os.getcwd()}\")\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"--- Google Drive monté ---\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du montage de Google Drive : {e}\")\n",
    "    try:\n",
    "        drive.mount(\"/content/drive\", force_remount=True)\n",
    "        print(\"--- Google Drive remonté avec succès ---\")\n",
    "    except Exception as e_remount:\n",
    "        print(f\"Erreur : {e_remount}\")\n",
    "        exit()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcZyBXxNkX1A"
   },
   "outputs": [],
   "source": [
    "# === 2. CONFIGURATION DES CHEMINS DE FICHIERS ===\n",
    "BASE_PROJECT_PATH = \"/content/drive/MyDrive/Stage_CEFREM_Salma_2025/\"\n",
    "DATA_PATH = os.path.join(BASE_PROJECT_PATH, \"Data\")\n",
    "\n",
    "INPUT_FILTERED_DATA_PATH = os.path.join(DATA_PATH, \"Meteo\", \"InSitu\", \"Filtered_1970_Consolidated_Meteo_GIS_Data.csv\")\n",
    "STATION_METADATA_PATH = os.path.join(DATA_PATH, \"Meteo\", \"InSitu\", \"Consolidated_All_Pyrenees_Stations_Metadata_StrictlyFiltered.csv\")\n",
    "safran_csv_path = os.path.join(DATA_PATH, \"Meteo\", \"SAFRAN\", \"Données SAFRAN Pyrénées filtré_Final.csv\")\n",
    "output_final_df_path = os.path.join(DATA_PATH, \"Combined_Data_For_Regression_Prepared.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQ2xMnUYkaOA"
   },
   "outputs": [],
   "source": [
    "# === 3. FONCTION DE RÉDUCTION DE MÉMOIRE ===\n",
    "def reduce_mem_usage(df, verbose=False):\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"   Mémoire initiale: {start_mem:.2f} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if 'int' in str(col_type):\n",
    "            temp = df[col].dropna()\n",
    "            if not temp.empty:\n",
    "                c_min, c_max = temp.min(), temp.max()\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "\n",
    "        elif 'float' in str(col_type):\n",
    "            temp = df[col].dropna()\n",
    "            if not temp.empty:\n",
    "                c_min, c_max = temp.min(), temp.max()\n",
    "                if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "        elif col_type == 'object' or pd.api.types.is_string_dtype(df[col]):\n",
    "            if df[col].nunique() / len(df[col]) < 0.5 and df[col].nunique() < 50000:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"   Mémoire après optimisation: {end_mem:.2f} MB \"\n",
    "              f\"({100 * (start_mem - end_mem) / start_mem:.2f}% de réduction)\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vr8FrV_xkffr"
   },
   "outputs": [],
   "source": [
    "# === 4. CHARGEMENT DES DONNÉES STATIONS ===\n",
    "df_combined_stations = pd.read_csv(INPUT_FILTERED_DATA_PATH, low_memory=False)\n",
    "df_combined_stations = df_combined_stations.rename(columns={\n",
    "    'NUM_POSTE': 'ID_STAT',\n",
    "    'ALTI_MNT': 'ALTI_MNT',\n",
    "    'SLOPE': 'Station_Slope_30m',\n",
    "    'ASPECT': 'Station_Aspect_30m'\n",
    "})\n",
    "df_combined_stations = df_combined_stations.drop(columns=['ID_STATION', 'NOM_USUEL', 'ASPECT_RAD', 'ASPECT_COS', 'ASPECT_SIN'], errors='ignore')\n",
    "df_combined_stations['DATE'] = pd.to_datetime(df_combined_stations['DATE'], errors='coerce')\n",
    "df_combined_stations['ID_STAT'] = df_combined_stations['ID_STAT'].astype(str)\n",
    "df_combined_stations = reduce_mem_usage(df_combined_stations, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2DjZFhUkiq0"
   },
   "outputs": [],
   "source": [
    "# === 5. MÉTADONNÉES STATIONS ===\n",
    "df_metadata = pd.read_csv(STATION_METADATA_PATH, low_memory=False)\n",
    "df_metadata = df_metadata.rename(columns={\n",
    "    'NUM_POSTE': 'ID_STAT',\n",
    "    'LAT': 'Station_Latitude',\n",
    "    'LON': 'Station_Longitude',\n",
    "    'ALTI': 'Station_Altitude_Obs'\n",
    "})\n",
    "df_metadata['ID_STAT'] = df_metadata['ID_STAT'].astype(str)\n",
    "df_metadata = df_metadata[['ID_STAT', 'Station_Latitude', 'Station_Longitude', 'Station_Altitude_Obs']].drop_duplicates()\n",
    "df_metadata.dropna(inplace=True)\n",
    "df_metadata = reduce_mem_usage(df_metadata, verbose=True)\n",
    "\n",
    "df_combined_stations = pd.merge(df_combined_stations, df_metadata, on='ID_STAT', how='left')\n",
    "df_combined_stations.dropna(subset=['DATE', 'ID_STAT', 'Station_Latitude', 'Station_Longitude',\n",
    "                                    'Station_Altitude_Obs', 'ALTI_MNT', 'Station_Slope_30m', 'Station_Aspect_30m'],\n",
    "                            inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kN-i5DcNkkLf"
   },
   "outputs": [],
   "source": [
    "# === 6. CHARGEMENT DES DONNÉES SAFRAN ===\n",
    "df_safran = pd.read_csv(safran_csv_path)\n",
    "df_safran = df_safran.rename(columns={\n",
    "    'PRENEI_Q': 'SAFRAN_Snowfall_daily_mm',\n",
    "    'PRELIQ_Q': 'SAFRAN_Precipitation_liquid_daily_mm',\n",
    "    'T_Q': 'SAFRAN_Temperature_daily_C',\n",
    "    'EVAP_Q': 'SAFRAN_Evaporation_daily_mm'\n",
    "})\n",
    "df_safran['DATE'] = pd.to_datetime(df_safran['DATE'].astype(str).str.replace('.0', ''), format='%Y%m%d', errors='coerce')\n",
    "df_safran.dropna(subset=['DATE'], inplace=True)\n",
    "\n",
    "transformer = Transformer.from_crs(CRS(\"EPSG:27572\"), CRS(\"EPSG:4326\"), always_xy=True)\n",
    "df_safran['SAFRAN_Longitude_grid'], df_safran['SAFRAN_Latitude_grid'] = transformer.transform(df_safran['LAMBX'].values, df_safran['LAMBY'].values)\n",
    "df_safran['SAFRAN_Grid_ID'] = df_safran['SAFRAN_Longitude_grid'].round(4).astype(str) + '_' + df_safran['SAFRAN_Latitude_grid'].round(4).astype(str)\n",
    "df_safran = reduce_mem_usage(df_safran, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xb3apBJkkndj"
   },
   "outputs": [],
   "source": [
    "# === 7. COUPLAGE DES DONNÉES SAFRAN AUX STATIONS ===\n",
    "tree = cKDTree(df_safran[['SAFRAN_Longitude_grid', 'SAFRAN_Latitude_grid']])\n",
    "stations_unique = df_combined_stations[['ID_STAT', 'Station_Longitude', 'Station_Latitude']].drop_duplicates()\n",
    "distances, indices = tree.query(stations_unique[['Station_Longitude', 'Station_Latitude']])\n",
    "stations_unique['Nearest_SAFRAN_Grid_ID'] = df_safran.iloc[indices]['SAFRAN_Grid_ID'].values\n",
    "\n",
    "df_combined_stations = pd.merge(df_combined_stations, stations_unique[['ID_STAT', 'Nearest_SAFRAN_Grid_ID']], on='ID_STAT', how='left')\n",
    "\n",
    "df_safran = df_safran.drop_duplicates(subset=['DATE', 'SAFRAN_Grid_ID'])\n",
    "df_final = pd.merge(df_combined_stations, df_safran,\n",
    "                    left_on=['DATE', 'Nearest_SAFRAN_Grid_ID'],\n",
    "                    right_on=['DATE', 'SAFRAN_Grid_ID'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVPKMpnMkpt_"
   },
   "outputs": [],
   "source": [
    "# === 8. CRÉATION DE FEATURES SUPPLÉMENTAIRES ===\n",
    "df_final.drop(columns=['Nearest_SAFRAN_Grid_ID', 'SAFRAN_Grid_ID'], inplace=True, errors='ignore')\n",
    "\n",
    "# Colonnes essentielles\n",
    "essentials = ['ID_STAT', 'DATE', 'Station_Latitude', 'Station_Longitude', 'Station_Altitude_Obs',\n",
    "              'ALTI_MNT', 'Station_Slope_30m', 'Station_Aspect_30m',\n",
    "              'SAFRAN_Temperature_daily_C', 'SAFRAN_Snowfall_daily_mm',\n",
    "              'SAFRAN_Precipitation_liquid_daily_mm', 'SAFRAN_Evaporation_daily_mm']\n",
    "df_final = df_final.dropna(subset=essentials)\n",
    "\n",
    "# Temporelles\n",
    "df_final['DATE_Year'] = df_final['DATE'].dt.year.astype(np.int16)\n",
    "df_final['DATE_Month'] = df_final['DATE'].dt.month.astype(np.int8)\n",
    "df_final['DATE_Day'] = df_final['DATE'].dt.day.astype(np.int8)\n",
    "df_final['DATE_DayOfYear'] = df_final['DATE'].dt.dayofyear.astype(np.int16)\n",
    "df_final['DATE_WeekOfYear'] = df_final['DATE'].dt.isocalendar().week.astype(np.int8)\n",
    "\n",
    "# Orientation sin/cos\n",
    "df_final['Station_Aspect_sin'] = np.sin(np.deg2rad(df_final['Station_Aspect_30m'])).astype(np.float32)\n",
    "df_final['Station_Aspect_cos'] = np.cos(np.deg2rad(df_final['Station_Aspect_30m'])).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMhj-4_1ksJ9"
   },
   "outputs": [],
   "source": [
    "# === 9. SAUVEGARDE DU FICHIER FINAL ===\n",
    "for col in df_final.select_dtypes(include='category').columns:\n",
    "    df_final[col] = df_final[col].astype(str)\n",
    "\n",
    "df_final.to_parquet(output_final_df_path, index=False, engine='pyarrow', compression='snappy')\n",
    "print(f\" Fichier final sauvegardé à : {output_final_df_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEYa14zIb0kw71EF4gvbbh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
